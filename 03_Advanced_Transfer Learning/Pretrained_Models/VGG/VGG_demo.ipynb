{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309067d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46561a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load VGG16 with pre-trained ImageNet weights\n",
    "# include_top=True means we keep the final classification layer (for 1000 classes)\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17143a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load and Preprocess Image\n",
    "# VGG requires 224x224 images\n",
    "img_path = 'test_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b3f71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to array and add batch dimension (1, 224, 224, 3)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# VGG specific preprocessing (subtracts mean RGB value)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1014d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Predict\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128053b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4fe81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def VGG_Block(x, filters, layers_num):\n",
    "    for _ in range(layers_num):\n",
    "        x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699241b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_vgg16(input_shape=(224, 224, 3), num_classes=1000):\n",
    "    inputs = layers.Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135427d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x = VGG_Block(inputs, 64, 2)\n",
    "    x = VGG_Block(x, 128, 2)\n",
    "    x = VGG_Block(x, 256, 3)\n",
    "    x = VGG_Block(x, 512, 3)\n",
    "    x = VGG_Block(x, 512, 3)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(inputs, outputs, name=\"VGG16\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
